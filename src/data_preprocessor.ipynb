{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b44645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48286709",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = ['mh2g', 'mh3u', 'mh4u', 'mhrs', 'mhwi', 'mhwilds', 'mhxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2793a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_within_rows(df, features_to_normalize, min_val=0):\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Select only the columns to normalize\n",
    "    features_df = df_normalized[features_to_normalize]\n",
    "    \n",
    "    # Min-max normalization: (x - min) / (max - min)\n",
    "    row_min = min_val\n",
    "    row_max = features_df.max(axis=1)\n",
    "    df_normalized[features_to_normalize] = features_df.sub(row_min, axis=0).div(row_max - row_min, axis=0)\n",
    "        \n",
    "    # Replace NaN values with 0 (occurs when std=0 or max=min)\n",
    "    df_normalized[features_to_normalize] = df_normalized[features_to_normalize].fillna(0)\n",
    "    \n",
    "    return df_normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ae7c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(df, features_to_normalize):\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    # Min-max normalization: (x - min) / (max - min)\n",
    "    for feature in features_to_normalize:\n",
    "        col_min = df[feature].min()\n",
    "        col_max = df[feature].max()\n",
    "        df_normalized[feature] = (df[feature] - col_min) / (col_max - col_min)\n",
    "\n",
    "    # Replace NaN values with 0 (occurs when std=0 or max=min)\n",
    "    df_normalized[features_to_normalize] = df_normalized[features_to_normalize].fillna(0)\n",
    "    \n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d66f0410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_dataframes(df1, df2, features_to_multiply):\n",
    "    # Verify DataFrames have same shape\n",
    "    if df1.shape != df2.shape:\n",
    "        raise ValueError(\"DataFrames must have the same dimensions\")\n",
    "    \n",
    "    # Verify specified columns exist in both DataFrames\n",
    "    for col in features_to_multiply:\n",
    "        if col not in df1.columns or col not in df2.columns:\n",
    "            raise ValueError(f\"Column '{col}' not found in both DataFrames\")\n",
    "    \n",
    "    # Create a copy of df1 to store results\n",
    "    result_df = df1.copy()\n",
    "    \n",
    "    # Multiply specified features\n",
    "    for col in features_to_multiply:\n",
    "        result_df[col] = df1[col] * df2[col]\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "67b639d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_combined(df, features_to_normalize):\n",
    "    normalized_by_rows = normalize_within_rows(df, features_to_normalize)\n",
    "    normalized_by_columns = normalize_columns(df, features_to_normalize)\n",
    "    return multiply_dataframes(normalized_by_rows, normalized_by_columns, features_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd3d3b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make weakness normalized csv\n",
    "\n",
    "features_to_normalize = ['fire_weak', 'water_weak', 'thunder_weak', 'ice_weak', 'dragon_weak']\n",
    "normalized_dfs = pd.DataFrame()\n",
    "\n",
    "for file_name in file_names:\n",
    "    df = pd.read_csv(f'../db/monster_weak/{file_name}_weak.csv')\n",
    "    normalized_df = normalize_combined(df, features_to_normalize).round(2)\n",
    "    normalized_df.to_csv(f'../db/monster_weak_norm/{file_name}_weak_norm.csv', index=False)\n",
    "    normalized_dfs = pd.concat([normalized_dfs, normalized_df], axis=0)\n",
    "\n",
    "# normalized_dfs.to_csv('normalized_weak.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e8f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make monsters.csv\n",
    "\n",
    "def remove_parenthesis(monster_name):\n",
    "    return monster_name.split(' (')[0]\n",
    "\n",
    "def get_monster_diff_states(monster_name, keys) -> list[str]:\n",
    "    result = []\n",
    "    for key in keys:\n",
    "        if remove_parenthesis(key) == monster_name:\n",
    "            result.append(key)\n",
    "\n",
    "    return result\n",
    "\n",
    "for file_name in file_names:\n",
    "    result = dict()\n",
    "    final_columns = [\"monster\", \"fire_weak\", \"water_weak\", \"thunder_weak\", \"ice_weak\", \"dragon_weak\"]\n",
    "    # First, look into monster weakness file (because it denotes monsters in different states)\n",
    "    with open(f'../db/monster_weak_norm/{file_name}_weak_norm.csv') as file:\n",
    "        # monster,fire_weak,water_weak,thunder_weak,ice_weak,dragon_weak\n",
    "        monsters_weakness = list(csv.reader(file))[1:]\n",
    "        for monster_weakness in monsters_weakness:\n",
    "            monster,fire_weak,water_weak,thunder_weak,ice_weak,dragon_weak = monster_weakness\n",
    "            result[monster] = {\n",
    "                \"fire_weak\": fire_weak,\n",
    "                \"water_weak\": water_weak,\n",
    "                \"thunder_weak\": thunder_weak,\n",
    "                \"ice_weak\": ice_weak,\n",
    "                \"dragon_weak\": dragon_weak\n",
    "            }\n",
    "    \n",
    "    # Now get monsters' other attributes\n",
    "\n",
    "    other_attributes = [\"type\", \"element\", \"size_pred\"]\n",
    "\n",
    "    for other_attribute in other_attributes:\n",
    "        # Remember to convert non-parenthesis to parenthesis if needed\n",
    "        with open(f'../db/monster_{other_attribute}/{file_name}_{other_attribute}.csv') as file:\n",
    "            instances = list(csv.reader(file))\n",
    "            columns = instances[0][1:]  # Exclude 'monster' feature\n",
    "            final_columns.extend(columns)\n",
    "            instances = instances[1:]  # Exclude headers\n",
    "\n",
    "            for instance in instances:\n",
    "                monster = instance[0]\n",
    "                features = instance[1:]\n",
    "                states = get_monster_diff_states(monster, result.keys())\n",
    "                for name in states:\n",
    "                    for i in range(len(columns)):\n",
    "                        result[name][columns[i]] = features[i]\n",
    "\n",
    "    # Convert result\n",
    "    result2 = []\n",
    "    for monster, values in result.items():\n",
    "        new_item = {\"monster\": monster}\n",
    "        for col in final_columns[1:]:  # Exclude 'monster' feature\n",
    "            new_item[col] = values[col]\n",
    "        result2.append(new_item)\n",
    "\n",
    "    with open(f'../db/monster/{file_name}.csv', 'w', newline='') as file:\n",
    "        keys = final_columns\n",
    "        writer = csv.DictWriter(file, fieldnames=keys)\n",
    "\n",
    "        writer.writeheader()\n",
    "        writer.writerows(result2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04e5adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make monster_fights.csv\n",
    "\n",
    "def has_parenthesis(monster_name):\n",
    "    return ' (' in monster_name\n",
    "\n",
    "def remove_parenthesis(monster_name):\n",
    "    return monster_name.split(' (')[0]\n",
    "\n",
    "\n",
    "monsters_columns = None\n",
    "monsters = []\n",
    "for file_name in file_names:\n",
    "    with open(f'../db/monster/{file_name}.csv') as file:\n",
    "        content = list(csv.reader(file))\n",
    "        if monsters_columns is None:\n",
    "            monsters_columns = content[0]\n",
    "        content = content[1:]\n",
    "        monsters.extend(content)\n",
    "\n",
    "same_monsters_dict = dict()\n",
    "for monster in monsters:\n",
    "    name = monster[0]\n",
    "    if has_parenthesis(name):\n",
    "        same_monsters_dict[name] = remove_parenthesis(name)\n",
    "\n",
    "fights = pd.read_csv('../db/fights.csv').values.tolist()\n",
    "monsters_columns_initiator = ['I_'+mc for mc in monsters_columns]\n",
    "monsters_columns_opponent = ['O_'+mc for mc in monsters_columns]\n",
    "csv_columns = []\n",
    "csv_columns.extend(monsters_columns_initiator[1:])\n",
    "csv_columns.extend(monsters_columns_opponent[1:])\n",
    "csv_columns.append(\"Outcome\")\n",
    "\n",
    "monsters_dict = {monster[0]: monster[1:] for monster in monsters}\n",
    "\n",
    "def find_same_monster(monster_name) -> list:\n",
    "    result = []\n",
    "    for key, value in same_monsters_dict.items():\n",
    "        if value == monster_name:\n",
    "            result.append(key)\n",
    "    return result\n",
    "\n",
    "result = []\n",
    "for fight in fights:\n",
    "    initiator, opponent, outcome = fight\n",
    "    initiator_data = []\n",
    "    opponent_data = []\n",
    "    \n",
    "    if initiator in monsters_dict and opponent in monsters_dict:\n",
    "        initiator_data = monsters_dict[initiator]\n",
    "        opponent_data = monsters_dict[opponent]\n",
    "        row_data = []\n",
    "        row_data.extend(initiator_data)\n",
    "        row_data.extend(opponent_data)\n",
    "        row = {column: data for data, column in zip(row_data, csv_columns[:-1])}\n",
    "        row[\"Outcome\"] = outcome\n",
    "        result.append(row)\n",
    "    else:\n",
    "        same_initiators = [initiator]\n",
    "        same_opponents = [opponent]\n",
    "        if initiator not in monsters_dict:\n",
    "            same_initiators = find_same_monster(initiator)\n",
    "        if opponent not in monsters_dict:\n",
    "            same_opponents = find_same_monster(opponent)\n",
    "        wars = []\n",
    "        for same_initiator in same_initiators:\n",
    "            for same_opponent in same_opponents:\n",
    "                wars.append((same_initiator, same_opponent))\n",
    "        \n",
    "        for war in wars:\n",
    "            initiator_data = monsters_dict[war[0]]\n",
    "            opponent_data = monsters_dict[war[1]]\n",
    "            row_data = []\n",
    "            row_data.extend(initiator_data)\n",
    "            row_data.extend(opponent_data)\n",
    "            row = {column: data for data, column in zip(row_data, csv_columns[:-1])}\n",
    "            row[\"Outcome\"] = outcome\n",
    "            result.append(row)\n",
    "\n",
    "with open('../db/monster_fights.csv', 'w', newline='',) as file:\n",
    "    keys = csv_columns\n",
    "    writer = csv.DictWriter(file, fieldnames=keys)\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
